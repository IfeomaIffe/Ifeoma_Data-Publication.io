<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-giJF6kkoqNQ00vy+HMDP7azOuL0xtbfIcaT9wjKHr8RbDVddVHyTfAAsrekwKmP1" crossorigin="anonymous">
    <link rel="stylesheet" href="css/final.css">

    <link rel="icon" type="image/svg" href="images/a.svg" />
    <title>Research Project</title>

    <style>
        hr {
            height: 9px;
            background-color: maroon;
        }
    </style>
</head>

<body>
    <!--Header-->
    <div cstyle="text-align: center;">
        <img class="img-fluid" type="image/svg" src="Asset 1.svg" alt="Ifeoma Abara" />
    </div>

    <!--Navigation-->
    <nav class="navbar navbar-expand-lg navbar-dark container-fluid">
        <a class="navbar-link" href="final.html" id="nav-link">Home</a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarTogglerDemo02" aria-controls="navbarTogglerDemo02" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon" style="color:white"></span></button>
        <div class="collapse navbar-collapse" id="navbarTogglerDemo02">
            <ul class="navbar-nav mr-auto me-auto mb-2 mb-lg-0">
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="nav-link" id="navbarDropdown" role="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Research</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                        <a class="dropdown-item" id="nav-link" href="final_about.html">About</a>
                        <div class="dropdown-divider" id="nav-link"></div>
                        <a class="dropdown-item" id="nav-link" href="contribute.html">Contribute</a>
                        <a class="dropdown-item" id="nav-link" href="future.html">Future Research</a>
                    </div>
                </li>
                <li class="nav-item">
                    <a class="nav-link" id="nav-link" href="map.html">Map</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" id="nav-link" href="critc.html">Critical Cataloging</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" id="nav-link" href="#">Presentation & Papers</a>
                </li>
            </ul>
        </div>
    </nav>

    <!--Img Header-->
    <div style="margin-bottom: 3em;">
        <img src="287.png" class=" img-fluid" alt="protestors">
    </div>

    <!--Text-->
    <div class="container">
        <h1 class="fs-2">Description of the project</h1>
        <h2>Overview</h2>
        <div>
            <p>American history holds an abundance poignant stories of resistance chronicled through images and hard data. Many of these stories are either oversimplified or, in most cases, never told. In the case of Emmett Till’s murder, there are few who
                know the full story. The authorities, in Money, Mississippi, where he was murdered, took extraneous efforts to keep and bury his body to conceal the atrocities inflicted upon his body, and to hide evidence. The images published of Till’s
                disfigured body would have never circulated the U.S, if it was not for Till’s mother, Mamie, demands to have his body sent back to his home Chicago, and insistence of having an open casket funeral. These images galvanized the civil rights
                movement and summon to mind on command.
            </p>
            <p>Ida B. Wells, is an exemplary case study of using data as an act of resistance through her collection of hard data of lynching of Black Americans and publication of A Red Record. Wells exposed how something that was generally perceived as
                a problem was, in fact, a pandemic. She showcased how data can illustrate concepts that tell a fuller story in a way that cannot be denied. Issues of censorship and authoritarian attempts to control who gets to “view” is still present
                today with the withholding of body camera footage exhibiting police brutality upon racialized Americans, predominantly Black Americans but this definition entails all minoritized groups. This is brought to the forefront, such as the case
                with Emmett Till, and in present case of George Floyd (among the many others this year), where once these visuals of police brutality are shared on social media by bystander witnesses, (and then officially released months later by public
                officials) revitalizes the demands of justice.</p>

            <p>The proportion of reporting throughout American history between white and racialized Americans, pertaining protest, rioting, and any display of public discontent is so indisputably skewed, that it can almost go unsaid. Because of the repetitive
                use of these images, it continues to manipulate what blackness means, and continuing the cycle; like the turning of a wheel. This continual pattern of negative connotations takes multiple forms, mainly it is embedded within language and
                overtime becomes a part of the collective memory and national story which is retold generation after generation. Thus, contorting and taking new shapes with each subsequent era. Scholars have been iterating this sentiment for generations,
                predominantly through qualitative research. Furthermore, there is still a dearth of data pertaining to marginalized groups (Kulman et al., 2020).</p>

            <p>With keeping these two cases in mind, among the many others, the primary focuses of my research is to collect and observe as many moments of civil unrest captured throughout American history and conduct close and distant reading of these images
                combined with data, to present a fuller and richer story. Newspapers images will be the text of study, in that many of these “iconic” moments of American history become apart collective memory and subsequently printed in history textbooks.
            </p>


            <hr class="container-fluid ">

            <h2>Research Goals</h2>
            <p>I am proposing for a mixed method computational algorithm of image and text retrieval pulled from American historical newspapers to present newspapers in circulation today. Specifically, to create an image detection algorithm focused on getting
                better recognition of persons with darker skin complexions. To ground this research, I plan on pulling methods and theories from a multitude of areas of study and will go through a short review of a few main ones to establish some context.
                I will conclude with evaluating how the algorithms pertain to my research goals. </p>

            <!--Add Goals-->
            <p>Pellentesque sagittis dui urna. Sed varius dictum imperdiet. Duis velit ante, eleifend eu dictum eget, egestas ac odio. Phasellus in nisi lectus. Quisque pharetra lacus risus. Ut rhoncus ex nulla, at auctor elit ullamcorper non. Quisque maximus,
                tellus sodales iaculis congue, leo risus venenatis neque, non tincidunt enim massa rutrum turpis. Nam odio nulla, hendrerit in leo et, porttitor imperdiet urna. Aenean tristique nisi sit amet volutpat cursus. Curabitur faucibus mi eros,
                at eleifend massa varius et. Ut pharetra mauris et congue efficitur.</p>

            <p>Aenean in nunc in urna varius aliquet. Fusce nec felis non sapien posuere molestie. Nulla id viverra mi. Phasellus dapibus quam non elit euismod auctor. Vestibulum tempor elit ac arcu fringilla tempor. Orci varius natoque penatibus et magnis
                dis parturient montes, nascetur ridiculus mus. Vestibulum non mi condimentum, gravida nulla ac, consectetur enim. Integer sollicitudin nulla ac ullamcorper pharetra. Integer commodo ac lectus sit amet tristique.</p>

            <!--Questions-->
            <h2>Research Questions</h2>
            <div class="clearfix ">
                <p>Who are the most represented, and what does this say? Who are represented as insiders/outsiders and how has this changed with time? What do these photos show about American journalism, and how are they reflective of the visual storytelling
                    of the present day? Do graphic images have the ability to alter public support for or against U.S. police systems and civil rights issues? Are we statistically telling and retelling the same stories? Are these the stories we want to
                    tell?
                </p>
                <!--Timeline-->
                <h2>Timeline</h2>

                <div class="container">
                    <img src="344.png" style="width: 50%; margin: 7px 0em; " class="col float-md-end ms-md-3 " alt="protestors " />

                </div>
                <h2>Methods and Literature Review</h2>
                <p>The project idea originating from the Newspaper Navigator dataset released by the Library of Congress, which has over 1.56 million visuals collected from over 16 million historic newspaper pages from 1850 - 1963. This dataset has been
                    made open access, along with pre-packaged datasets and the corresponding code available for public use. The datasets organized by year include images, cartoons, advertisements, and other visual content types. In addition, including
                    textual content a headline; likewise, for a photograph, illustration, or map, this textual representation often contains the title and caption, Place of Publication, Geographic Coverage, Newspaper Name, Newspaper Publisher, and other
                    metadata fields. However, because it is lacking in an adequate representation, its complete use for my study is no longer an option. This problem is addressed by its creator Benjamin Lee in his findings, </p>

                <!--Blockquote-->
                <figure class="text-start" style="margin:5 0em; ">
                    <blockquote class="blockquote ">
                        While this loss in image quality is marginalizing in its own right, image embeddings perpetuate this marginalization: digitized newspaper portraits of darker-skinned individuals are more likely to suffer from saturated facial features, in turn resulting
                        in these photographs being lost during the discovery and retrieval process… Though machine learning methods are often offered as panaceas for automation, this algorithmic erasure reminds us that traditional methods of scholarship
                        and historiography, such as detailed analyses and close readings of Black newspapers in Chronicling America, are more important than ever to counter algorithmic bias (Lee, 2020, p.28).
                    </blockquote>
                    <figcaption class="blockquote-footer ">
                        Benjamin Charles Germain Lee, Jaime Mears, Eileen Jakeway, Meghan Ferriter, Chris Adams, Nathan Yarasavage, Deborah Thomas, Kate Zwaard, Daniel S. Weld<cite title="Source Title ">The Newspaper Navigator Dataset: Extracting And Analyzing Visual Content from 16 Million Historic Newspaper Pages in Chronicling America<a href="https://arxiv.org/abs/2005.01583"></a></cite>
                    </figcaption>
                </figure>
                <p>Deriving from this project, I am proposing to create my own of database from first the Library of Congress API, in addition to many other APIs to locate images pulled from all newspapers, but with the specific concentration on newspapers
                    from racialized populations, where there remains a difficulty of image detection precision. The datasets will be constructed this way, one of mainly white newspapers, and one oia collection of newspapers from various subcultures of
                    racialized Americans from the 1880s to present, where sets will be grouped by every 20 years.</p>

                <p>First, I will need to do further research into language creation of race and formulate an ethical codifying system. As stated by Martin Berger, in the introduction to his book, Seeing Through Race, “In order to conduct a computation analysis
                    of a large, digitized corpus of photographic materials, it is necessary to develop a code system for describing each image” (2011, p.11). I am thinking I may also need to construct a timeline featuring all the occurrences of civil
                    unrest in American history, in addition to a taxonomy for mapping relationships between words, and their connotations along with metadata tags. This could be transferred to an ontology to organize how words have changed over time,
                    also to describe the data models and map how they are to be used. I believe this is help simplify and organize the compounding computational theories and methods.</p>

                <p>Subsequently, I will need to conduct several rounds of web scrapping to build an alternative dataset, apart from the APIS, of present-day newspaper images. With this, I am thinking of expanding upon the textual data that is currently not
                    available in the Newspaper Navigator datasets, also whether I should include digital images from newspaper/media websites. Once a sizable corpus has been collected, I plan to use data management tools such as OpenRefine, to do clean
                    up and Libre Office quickly review data and run smaller tests of various image recognition models, while I continue building the corpus. </p>

                <p>Once the corpus has been complied, a computational image detection algorithm(s) has been finalized, and the data analysis model has proved promising, I will then use MySQL, to run more detailed queries on all the data. The next step would
                    be to run iterations of the imaging programs and use Jupyter Notebook to analyze the statistical outputs, and run a multivariate regression or Principle Component Analysis, in addition to using it to create data visualizations. There
                    are many algorithmic options for image detection, some focusing on facial features, or the whole images, or for parsing out elements within the image, and others for evaluating artistic content and style. </p>

                <p>The first is being Computational Grounded Theory (CGT) which is relatively new. As proposed by researcher Laura K. Nelson, takes into account aspects from both traditional Content Analysis (CA) and Computer-assisted Content Analysis (CCA)
                    mixed with Grounded theory. “Grounded theory is a method designed to allow categories and themes to emerge inductively from data, culminating in data-driven but abstract theoretical understandings of the underlying social world” (p.5).
                    The traditional qualitative practice of CA uses coding – this process is clearly construed by Nelson,</p>

                <!--Blockquote-->
                <figure class="text-end " style="margin:5 0em; ">
                    <blockquote class="blockquote ">
                        <p>[As a way to] increase accuracy, multiple coders will code the same text and their agreement on codes is checked via an intercoder reliability score. When the text is coded with a reasonably high intercoder reliability (or, sometimes,
                            by one expert researcher), the researcher then analyzes the coded text, looking for different types of patterns within and between texts.</p>
                    </blockquote>
                    <figcaption class="blockquote-footer ">
                        Laura K. Nelson<cite title="Source Title ">2020, p.6</cite>
                    </figcaption>
                </figure>

                <p>Attempting to interpret the text holistically is a difficult task, because according to Nelson there is no way to make linguistic coding scientific. According to Nelson, the process itself obscures rather than reveals what the researcher
                    is trying to say because it is relatively experimental in nature, and in many cases completely unreproducible (p.7). Nelson proposes CCA will make up for the limitations of content analysis, by using computational techniques like pattern
                    detection and pattern refinement with Guided Deep Reading to crate lexical selection and topic modeling (p.14). I believe the CGT method would be well suited for the textual content collected.</p>
                <button type="button" class="btn btn-outline-dark"><a  style="text-align:center;" src="#">Read more</a></button>


                <!--Linebreak-->
                <hr>

                <h2>Critical Cataloging and Metadata Research</h2>
                <p>Sed bibendum, augue vitae volutpat tincidunt, leo ante commodo mauris, ut pellentesque eros nulla placerat erat. Aenean nibh purus, tincidunt in condimentum vel, pulvinar vitae quam. Cras id ante dictum, finibus ipsum ut, tristique massa.
                    Integer congue at ipsum tincidunt placerat. Pellentesque non arcu eget diam lacinia semper. Fusce vestibulum porttitor vehicula. Integer quis scelerisque tortor.</p>

                <p>Nullam volutpat augue sodales, commodo urna sit amet, tempor mi. Morbi imperdiet elit at nisi vestibulum placerat. Nullam nec augue rhoncus, placerat odio quis, hendrerit tellus. Nullam nec sem augue. Etiam viverra, risus at facilisis
                    convallis, magna metus pharetra leo, in finibus diam sapien a magna. Aliquam nec efficitur lorem. Cras sit amet urna sagittis, rutrum erat iaculis, congue eros. Sed metus magna, tristique et justo efficitur, ornare viverra sem.</p>
                <button type="button" class="btn btn-outline-dark"><a  style="text-align:center;" href="https://ifeomaiffe.github.io/Ifeoma_Data-Publication.io/research%20website/final_about.html#current">Read more</a></button>

            </div>
        </div>

    </div>

    <!--Footer-->
    <div class="row " style="margin-top: 5px; ">
        <p style="text-align: center; ">&COPY; Ifeoma Abara // University of Chicago</p>
    </div>

    <!--Javascript-->
    <div>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta1/dist/js/bootstrap.bundle.min.js " integrity="sha384-ygbV9kiqUc6oa4msXn9868pTtWMgiQaeYH7/t7LECLbyPA2x65Kgf80OJFdroafW " crossorigin="anonymous "></script>
    </div>
</body>

</html>